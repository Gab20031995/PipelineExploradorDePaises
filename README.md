![LOGO ULEAD](https://github.com/user-attachments/assets/6f54a45a-9049-4952-8bd9-ffe2d4983bf3)

# **2025- II Programaci√≥n Web**
# **Entregable grupal #4**

## Profesor: Alejandro Zamora Esquivel

Alumnos:
- Gabriel Corrales Mora.
- Jeralin Mayerlin Flores Hern√°ndez.
- Jean Rabbat S√°nchez.

# üåé Explorador de Pa√≠ses

**DEMO:**

Un proyecto de aplicaci√≥n web full-stack que permite a los usuarios explorar, buscar y guardar informaci√≥n sobre pa√≠ses de todo el mundo. La aplicaci√≥n consume datos de la API p√∫blica [REST Countries](https://restcountries.com/) y utiliza una base de datos propia para gestionar la lista de pa√≠ses favoritos de cada usuario. **Adem√°s, ahora podr√°s consultar el clima actual en tiempo real de cada pa√≠s, con datos actualizados y procesados por un robusto pipeline de datos.**

## Caracter√≠sticas

* **Exploraci√≥n Global:** Visualiza una lista completa de pa√≠ses con sus banderas.
* **B√∫squeda Din√°mica:** Busca pa√≠ses espec√≠ficos por su nombre.
* **Filtros Avanzados:** Filtra la lista de pa√≠ses por regi√≥n (√Åfrica, Am√©rica, Asia, etc.) y subregi√≥n (Norteam√©rica, Caribe, etc.).
* **Detalles del Pa√≠s:** Haz clic en un pa√≠s para ver informaci√≥n detallada como su capital, poblaci√≥n, moneda e idioma principal.
* **Informaci√≥n Meteorol√≥gica en Tiempo Real:** Consulta la temperatura, velocidad del viento y hora de la √∫ltima medici√≥n para cada pa√≠s. Los datos se actualizan autom√°ticamente cada minuto y pueden ser forzados con un bot√≥n de "Consultar Clima" en el modal de detalles. Se incluye un indicador visual de carga (spinner) mientras se obtienen los datos.
* **Pipeline de Datos Integrado (ETL):** Un sistema ETL (Extracci√≥n, Transformaci√≥n, Carga) automatizado se encarga de procesar los datos meteorol√≥gicos crudos obtenidos de la [Open-Meteo API](https://open-meteo.com/). Este pipeline limpia, valida y almacena los datos de forma optimizada en una tabla separada, adem√°s de generar backups y logs de calidad.
* **Gesti√≥n de Favoritos:** Guarda tus pa√≠ses preferidos en una lista personalizada y elim√≠nalos cuando quieras.
* **Modales Personalizados:** Los mensajes de confirmaci√≥n y alerta ahora se muestran en modales personalizados para una mejor experiencia de usuario.
* **Interfaz Limpia y Responsiva:** Dise√±o moderno y adaptable a diferentes tama√±os de pantalla.

## Tecnolog√≠as Utilizadas

Este proyecto est√° construido con las siguientes tecnolog√≠as:

### Frontend
* **HTML:** Para la estructura sem√°ntica de la aplicaci√≥n.
* **CSS:** Para el dise√±o y la apariencia visual, incluyendo animaciones para el spinner y modales.
* **JavaScript (ES6+):** Para la interactividad, la manipulaci√≥n del DOM y la comunicaci√≥n con el backend.

### Backend
* **Python:** Como lenguaje de programaci√≥n del servidor.
* **FastAPI:** Un framework web moderno y de alto rendimiento para construir APIs con Python.
* **Uvicorn:** Como servidor ASGI para correr la aplicaci√≥n FastAPI.
* **httpx:** Cliente HTTP as√≠ncrono para realizar peticiones a APIs externas (REST Countries, Open-Meteo).

### Base de Datos
* **MySQL:** Para almacenar la lista de pa√≠ses guardados por el usuario, as√≠ como los datos meteorol√≥gicos crudos y limpios.
* **mysql-connector-python:** Conector de Python para interactuar con MySQL.

### Pipeline de Datos (ETL)
* **Python Scripting:** Implementado como un script Python puro (`pipeline/flow.py`) para las etapas de Extracci√≥n, Transformaci√≥n y Carga (ETL) de los datos meteorol√≥gicos.
* **Pandas:** Utilizado para la manipulaci√≥n y limpieza eficiente de los datos dentro del pipeline.

## Instalaci√≥n y Puesta en Marcha

Para ejecutar este proyecto en tu m√°quina local, sigue estos pasos:

### Prerrequisitos

Aseg√∫rate de tener instalado:
* **Python 3.8 o superior**
* **pip** (el gestor de paquetes de Python)
* Un servidor de **MySQL** en ejecuci√≥n

### 1. Configuraci√≥n del Backend

Primero, clona el repositorio y configura el servidor de Python.

```bash
# 1. Clona el repositorio si lo tienes en Git
git clone https://github.com/Gab20031995/PipelineExploradorDePaises.git
cd <NOMBRE_DE_LA_CARPETA>

# 2. Crea y activa un entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows usa: venv\Scripts\activate

# 3. Instala todas las dependencias de Python desde el archivo requirements.txt
pip install -r requirements.txt

4. Configura las Variables de Entorno de la Base de Datos
Importante: Para la seguridad y flexibilidad, las credenciales de la base de datos se leen de variables de entorno, no est√°n codificadas en el c√≥digo. Debes configurarlas en tu terminal antes de iniciar el servidor.

En Linux / macOS:

export DB_HOST="127.0.0.1"
export DB_PORT="3307" # Aseg√∫rate de que este sea el puerto correcto de tu MySQL
export DB_USER="root"
export DB_PASSWORD="tu_contrase√±a_mysql"
export DB_NAME="countries_db"

En Windows (PowerShell):

$env:DB_HOST="127.0.0.1"
$env:DB_PORT="3307"
$env:DB_USER="root"
$env:DB_PASSWORD="tu_contrase√±a_mysql"
$env:DB_NAME="countries_db"

(Si cierras la terminal, estas variables se perder√°n. Para una soluci√≥n m√°s persistente en desarrollo, puedes investigar el uso de la librer√≠a python-dotenv.)

5. Inicia el servidor Backend
uvicorn main:app --reload

El backend ahora estar√° corriendo en http://127.0.0.1:8000. La aplicaci√≥n crear√° autom√°ticamente la base de datos countries_db (si no existe) y las tablas saved_countries, weather_raw_data, y weather_cleaned_data al iniciar.

6. Disparo Manual del Pipeline (Opcional)
Puedes forzar la ejecuci√≥n del pipeline de clima para todos los pa√≠ses con datos crudos o guardados enviando una petici√≥n POST a este endpoint:

curl -X POST [http://127.0.0.1:8000/api/pipeline/run-weather-etl](http://127.0.0.1:8000/api/pipeline/run-weather-etl)

2. Iniciar el Frontend
Simplemente abre el archivo index.html en tu navegador web preferido. El JavaScript est√° configurado para comunicarse con el servidor local que acabas de iniciar.

Estructura del Proyecto
‚îú‚îÄ‚îÄ index.html          # Archivo principal de la interfaz
‚îú‚îÄ‚îÄ style.css           # Hoja de estilos
‚îú‚îÄ‚îÄ script.js           # L√≥gica del frontend y llamadas a la API
‚îú‚îÄ‚îÄ main.py             # Servidor backend con FastAPI y l√≥gica de negocio
‚îú‚îÄ‚îÄ pipeline/           # Contiene el script del pipeline de datos
‚îÇ   ‚îî‚îÄ‚îÄ flow.py         # L√≥gica de Extracci√≥n, Transformaci√≥n y Carga (ETL) para el clima
‚îú‚îÄ‚îÄ requirements.txt    # Lista de dependencias de Python
‚îî‚îÄ‚îÄ README.md           # Este archivo
